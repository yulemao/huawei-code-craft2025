# huawei-code-craft2025

2025华为软件精英挑战赛全球总决赛亚军 0b1000100 题解。主要代码在 `src` 目录下面。由于决赛时间较短，单人作战时间还是比较紧，决赛第二阶段基本上没能利用上离线的性质。如有需要可以参考本次比赛冠军也是我 ACM 队友 [知乎@孙咖啡](https://www.zhihu.com/people/sun-ming-zhi-91) 的代码 [https://github.com/sunkafei/huawei-software-challenge2025](https://github.com/sunkafei/huawei-software-challenge2025)。

`solution.cpp` 本意是为第二阶段重新设计算法使用的，但是实际并未做太多改动，因此有较多代码和 `main.cpp` 是重复的，具体针对第二阶段的优化可以参考题解中的说明。

### 磁盘规划与写入

每个磁盘被划分为 $B$ 个块，其中每个块都在另外两个磁盘上存在两个存储的 object 与其完全一致的块（块内部具体数据存储的顺序并不需要完全一致）。当然也可以采用每个块不需要一致的方式，但是在初赛的数据中，一致的方式在更为插入删除更为混乱的数据上表现略微好了一点，同时在后续的一些优化中编写同时兼容两种方式的代码过于繁琐，因此最终只采用了这一种方式。块的绑定为完全随机确定。

**确定 object 的存放位置**。根据题目中的描述，同一种 tag 的 object 的读取性质更为接近。这意味着需要尽量将同一种 tag 的 object 存放在一起，这样可以使得读取的时候更容易出现连续读取的情况。最直接的想法就是，每个块中允许存储的 tag 的数量应尽量的少。因此可以对每个块进行标记，标记该块允许存储哪些 tag。最开始每个块只被分配一个 tag。存储的过程中每个 tag 的 object 数量会有很大变动，插入的时候是连续插入的，但是删除的时候是近乎均匀的删除，导致出现很多的空隙。在一段时间后将无法满足所有的块只存储一个 tag。此时可以寻找一个已经有的 tag 数量尽量少，且剩余空间尽量大的块打上新的 tag 标记。同时为了尽量减少空隙，可以通过固定每个 tag 在存储时尝试块的顺序，这样使得每个 tag 对应的块都存在一个确定的降序排列。为了让磁盘尽可能的均匀，对于每一个 tag 均随机了一个尝试磁盘的顺序。在决赛第一阶段的强在线条件下，可以直接随机所有的块的顺序以达到均匀的效果。这些随机在初赛的条件下可能会起到反作用，但是在复赛加入超时倒扣分之后，均匀的磁盘可以使得每个时刻每个磁盘的读取压力更为接近，减少有磁盘空闲但其他磁盘读取压力过大的情况。

**块内的插入**。采取顺序访问的方式。当存在连续的空白位置可以插入当前 object 时，将 object 插入。如果磁盘剩余容量大于 object 大小但是没有可用的连续空间，此时会将 object 插空存储。

**存在离线先验时的预分配与优化**。在初赛复赛以及决赛的第二阶段，提供了每 1800 时间片甚至更细的信息。这部分信息可以用于预分配块所存储的第一个 tag。预分配的策略很简单，通过已知的信息确定第一次磁盘需要给一个块打上第二个 tag 时的块分配情况，并在每个磁盘上对所有的块进行排序，让同一个 tag 的块尽量接近，以减少 Jump 的次数。同时通过已知的写入删除信息结合每个 tag 固定的块写入顺序也可以确定，某一个 tag 在某一时刻过后，会存在某个块的存储空间不会继续增长只会减少的情况。这时可以在别的 tag 寻找新的块时优先把这个块分配给其他的 tag（这一优化应该可以缓解复赛正式赛那种增删更为密集的数据导致算法得分大幅下降的问题）。

### 读取

**r 和 p的选择**。考虑在读取时，如何合理规划 r 和 p。由于一个块内，存储的tag数量比较少，当存储较为均匀时，期望每个数据单元上的请求数量是较为接近的。所以块内当确定需要读取一个块时，一定会读取块内所有有请求的数据。这样一来首先确定了所有有请求的数据单元都是 r。但是空白的数据单元并不一定都是 p。例如 $101$ 三个数据单元采用 $rpr$ 的可能花费可能是 $16 + 1 + 64 = 81$，而全部都读取的花费则是 $16 + 16 + 16 = 48$。这种情况读取空白的数据单元也可以获得更好的结果。 

为了解决上述问题，可以使用一个 DP 来最大化读取的操作。

令 $f[i][j]$ 为读取了 $i$ 块，下一次读取所需要的 token 数为 $j$，所需要的最少总 token 数量。则当 $i$ 单元存在请求时，本次操作必定为 `r` ，所以有转移方程：

$$f[i][max(16, ceil(0.8 * j)] = f[i - 1][j] + j$$

当 $i$ 单元不存在请求时，则除了上式的转移方式外，还需增加操作为 `p` 的转移方式，即

$$f[i][64] = \min_{j=16}^{64}f[i - 1][j] + 1$$

在满足 $f[i][j] \leq G$ 的同时 $i$ 尽量大、$j$ 尽量小的解即为本次读取的最优策略。

为了考虑下一个时间片的需求，在实际题目中需要多向后 DP 一小段（如多 500 个token）然后再取最优解。

如果想要获得更快的运行速度的话，可以将这个 DP 进一步的修改。在读到一个位置后，可以通过他后面的连续 $k$ 个数据单元的状态来判定是否要对当前单元进行读取。用 1 表示存在请求，0 表示不存在请求，则这连续的 $k$ 个数据单元可写成一个 01 串 $s$。最优的读完这 $k$ 个数据单元的方法可以使用前述的 DP 进行解决。当 $k$ 不大的时候，所对应的 $s$ 的数量其实是有限的。因此可以使用 DP 对任意一种 01 串进行预处理。然后在实际读取的时候便可以 $O(1)$ 查询来判断当前数据单元是 r 还是 p。实测决赛练习赛数据中，当 $k=10$ 时会损失 3 万分，当 $k \geq 20$ 的时候分数损失会小于 5000 分。

**Jump 策略**。首先考虑什么时候允许 Jump 操作。因为根据存储的策略，每个块存储的 tag 数量很少，且经过一段时间的插入删除后会比较均匀。这意味着一旦允许读取了某个块，那么处理掉这个块所有的请求一定是一种可以接受的策略。这样一来当每个块被完全处理，即指针到块结束没有请求，或进入了新的块时，可以尝试判断是否需要 Jump。

接下来考虑何时 Jump，Jump 到哪里。首先可以注意到为了不让多个磁盘上的副本以及本磁盘的这若干个指针打架，首先要对每个指针未来能处理的一段 object 进行锁定处理（实际代码中为当前块中还未读取的 object），不允许别的指针跳转到这些 object 的位置上。同时每个块都是按顺序存储的，因此可以直接 Jump 到块的首地址上。

假设所有的请求都能被完成的情况，根据得分公式，并不是优先完成请求总分最高的块最优，而是同时间内完成 size 总和尽量大的请求更优。更详细的，$f(x)g(size)$ 对经过的时间进行求导，可以得到导数和 $(size + 1)$ 正相关。因此在考虑 Jump 的时候，每个块所对应的权重应当为块中的所有活跃请求所对应的 object 的 $(size + 1)$ 之和，并可以 Jump 到尽量大的块上。

但是由于 Jump 需要耗费一整个时间片，因此对于是否 Jump 可以使用一个可调参数 $k_{JMP}$ 进行控制。当这个指针接下来要读取的块的权重乘上 $k_{JMP}$ 会超过最大的块权重时，不执行 Jump。

在复赛之后，由于存在超时会倒扣分数的情况，因此需要在已有的块权重基础上，乘上上一次访问这个块所距离的时间。让 Jump 的时候考虑到快要超时的块。具体公式可以参考代码。

**超时预测**。在复赛之后，加入了超过 105 个时间片超时倒扣分的条件。首先可以想到的是，由于系统中存在 20 个指针，同时还有 Jump 等操作，导致已经进入系统的请求很难预测到底会不会超时。因此可以想到，对于每个请求，应当在进入系统的时候也就是第 0 时刻就判定是否需要丢弃，这时候也是负担最低的（倒扣分为 0）。如果没在一进入系统的时候就判断出来，那就等 105 时刻超时并报告即可。

考虑确定哪些请求需要丢弃。最直观的想法就是通过每个 tag 在一段时间的读取频率去卡阈值来删掉一些 tag 的全部请求。这样做在复赛中已经可以取得很可观的得分。但是它的不够精细，容易删多或者删少，同时也会在单个块存在多种标签时造成大量空隙，而且决赛第一阶段中大量标签无标记时可能会出现较大问题。

另一种稍微复杂一点但更契合写入策略的方法是屏蔽一些块使得其无法获得新的请求，在不影响块这一单位的情况下进行丢弃请求。比较显然的思路显然是和 Jump 的时候一样，计算每个块的权重，然后按照块的权重排序，删掉权重较小的块。与 Jump 的时候不一样，在这里计算的时候不能使用当前活跃的请求，而是统计历史请求。在决赛时这个时间被设置为 300 个时间片。而决赛第二阶段可以进一步优化，通过过去 200 个时间片和未来 200 个时间片来计算每个块的期望权重，并按照期望权重排序。在排序可以注意到，因为系统每时每刻都在变化，会导致排序会有一些波动，这可能会导致在边界的几个块处在一个屏蔽与不屏蔽的波动状态，这反而会导致块内的数据非常的不稳定。为了避免这个问题影响性能，设置每 200 个时间片才重新计算一遍要屏蔽哪些块。

再来考虑如何设置阈值。一个直接的思路是利用 token 进行计算。假设剩余的每个块每 105 个时间访问一次，那么可以直接通过最近的 105 个时间片的历史请求来计算出每个块走完需要多少 token。由于三个绑定的块的内部排列受到垃圾回收的影响不一定完全一致，在此可以直接取三个块的均值来当作这个块所需要消耗的 token。设置一个简单的上界 $N \times 105 \times G \times POINTER\_NUM \times REP\_NUM$ 即可取得一个还可以的结果了。但注意到这个时候还是有不小的 busy 百分比。这是因为存在一些块，由于请求数量过多，在 Jump 的时候会被访问超过一次，同时实际 token 消耗会和预估的消耗有出入。因此首先给上界加入一个可调参数 $k_{discard}$，根据数据进行调整。然后对于权重较大的块，定义一个对数函数计算其所消耗的 token。即当某个块的权重大小是当前确定保留的权重最小的块的 $x$ 倍，那其消耗的 token 为 $1.0 + k_d\log_2{x}$，其中 $k_d$ 也是一个可调整参数。实际上一个块并不会被访问很多次，因此这个函数只是一个可行的函数，有可能会有更贴合的函数，在此不做详细讨论。对于三个块未进行绑定的情况，也是可以通过动态调整块的权重进行计算的，但写起来会稍微麻烦一点。

### 垃圾回收

垃圾回收由于给的交换次数较小，所以其实能做到的事情较少。由于块绑定的存在，在此只考虑首先将块内尽可能整理。对于每个块通过双指针将靠后存有 object 的数据单元向前调换即可。而块的顺序通过计算每个块内空白和有数据的切换的次数按从多到少排序即可。由于每个请求的得分是按照最后一个数据单元被读取的时间确定的，同时一个块只要读必定会读完，所以这样调换使得 object 不够连续并不会影响系统性能。

在决赛第一阶段的时候可以加入优先调整确定 tag 的块来获得一定的小提升。

### Tag 预测

决赛的 tag 预测通过统计每 1800 时间片的读写数据，计算个时间段每种 tag 在某一数据单元上的平均请求数，可以构造出来一个向量。使用简单的欧氏距离计算即可获得一个很好的预测结果。虽然和给的数据的 tag 并不完全一致，但是在超时预测时，可以发现预测后使用期望会提升分数，而第一阶段使用期望会降低分数。这证明取得的预测已经较为贴合实际需求。

还有一个方法是参考设置阈值卡 tag 进行超时预测，对每 1800 个时间片计算要保留的 tag。对于每个 tag 可以获得一个读与不读的 01 串。使用同样的阈值对目标 object 计算，并和每一个 tag 计算异或差距。这一方法本质也是通过尽量将读取相近的 object 分类到一起，是前一方法的量化版本。在决赛练习赛上能取得更好的成绩，但是决赛正式赛上会略差一点点。

### 迭代优化

在决赛的第二阶段也可以使用迭代优化进行一定处理，由于时间限制在此只使用了一个比较简单直观的方法。在一次完整的计算后，可以发现有一些 object 的所有的请求都没有被处理。这时把这些 object 在下一次迭代的时候都打标记并作为垃圾存储到一段垃圾区域，并不再处理这些 object 的请求。这样一个简单的迭代可以取得一点点的提升。由于存在随机的影响所以这个优化并不能获得较为稳定的提升。根据实际测试决赛练习赛的提升要高于正式赛。正式赛的提升非常小。

---

上述的思路为比较关键的一些思路，可能会有一些遗漏的小技巧，具体还请参考代码。代码中有些部分可能写的比较随意比较丑陋还请见谅。

总体而言由于决赛实际只有四天时间准备，单人作战还是有些吃力，代码更多的还是基于复赛的代码按照决赛要求简单修改了一下。第二阶段本质还是在线方法，只是利用了一点未来数据进行了预测。更多的离线算法优化还请参考其他队伍的思路。
